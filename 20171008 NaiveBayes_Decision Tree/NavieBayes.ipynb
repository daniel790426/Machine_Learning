{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes 理論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這邊是貝氏定理的數學表達式<BR>\n",
    " ### $ \\displaystyle P(A|B)= \\frac {P(B|A)*P(A)}{P(B)}$ <BR>\n",
    " 在這個章節中，作者舉了一個簡單的例子：<br>\n",
    " ### <span style=\"color:red\">情境說明</span><BR>\n",
    " 在一個生產板手的工廠中，有兩台機器負責生產板手，有一天把兩台機器的生產的板手混成一堆，發現裡面有一些不良的板手，而目前已知的條件有：<br>\n",
    " 機器1 每個小時可以生產30支板手。<br>\n",
    " 機器2 每個小時可以生產20支板手。<br> \n",
    " 整體的不良率為 1%，並且機器1與機器2生產的不良品分別佔全部的50%。<br>\n",
    " <span style=\"color:blue\">請問</span>：從機器2生產的板手為不良品的機率為何?<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將上面的資訊轉換為數學表示：<br>\n",
    "兩台機器每個小時總共可以生產 20+30=50 支板手<br>\n",
    "所以抽到機器1生產的板手，機率為：$ \\displaystyle P(Mach1)=\\frac{30}{50}= 0.6 $<br>\n",
    "\n",
    "抽到機器2生產的板手，機率為：$ \\displaystyle P(Mach2)=\\frac{20}{50}= 0.4 $<br>\n",
    "\n",
    "抽到不良品的機率為：$ P(Defect)=0.01 $<br>\n",
    "\n",
    "不良品為機器1的機率為：$ P(Mach1| Defect)=0.5$ <br>\n",
    "\n",
    "不良品為機器1的機率為：$ P(Mach2| Defect)=0.5$ <br>\n",
    "\n",
    "要求解機器2中為不良品的機率為： <span style=\"color:red\">$P(Defect|Mach2) = $</span> ?<hr>\n",
    " ### $ \\displaystyle P(Defect|Mach2)= \\frac {P(Mach2| Defect)*P(Defect)}{P(Mach2)}= \\frac {0.5*0.01}{0.4}=0.0125=1.25$%  <BR>\n",
    " \n",
    "接著作者用了比較直觀的方式呈現，帶入實際的數值：<br>\n",
    "假設工廠總共生產了1000支板手，\n",
    "那因為 機器1 每個小時可以生產30支板手。<br>\n",
    "機器2 每個小時可以生產20支板手，生產來自機器2的就是：$\\displaystyle \\frac{1000}{(20+30)}*20=20*20=400$<br>\n",
    "而整體的不良率為 1% ： $1000*0.01=10$<br>\n",
    "不良品中來自機器2的機率為50%：$10*0.5=5$<br>\n",
    "所以機器2中為不良品的機率為：$\\displaystyle \\frac{5}{400}=0.0125=1.25$%<br>\n",
    "其實和上面的例子是一樣的<br>\n",
    " ### $ \\displaystyle P(Defect|Mach2)= \\frac {P(Mach2| Defect)*P(Defect)}{P(Mach2)}= \\frac {0.5*0.01*1000}{0.4*1000}=1.25$ %<BR>\n",
    "接下來作者提了一個疑問，**為什麼不直接去計算來自機器2有缺陷的板手去除以機器2呢?**<br>\n",
    "第一：<span style=\"color:red\">**耗時**</span>，因為你需要一個一個去判斷是好是壞。<br>\n",
    "第二：當遇到<span style=\"color:red\">**破壞性實驗**</span>沒辦法將全部的東西都拿下去做實驗。<br>(PS：何為破壞性實驗呢?例如：測驗燈泡的使用壽命，就需要將燈泡使用到壞掉。)<Hr>\n",
    "並且作者在這邊列了一個練習題：求解機器1中為不良品的機率為： <span style=\"color:red\">$P(Defect|Mach1) = $</span> ?<br>\n",
    " ### $ \\displaystyle P(Defect|Mach1)= \\frac {P(Mach1| Defect)*P(Defect)}{P(Mach1)}= \\frac {0.5*0.01}{0.6}=0.0083=0.83$ % <BR>\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Navie Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這是一般兩個$X$變數的分類問題的例子：\n",
    "![](images/NaiveBayes1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來作者舉了一個例子讓我們更容易理解，並且將這個例子拆成幾個步驟來呈現：\n",
    "![](images/NaiveBayes2.PNG)\n",
    "這是一個給定兩個特徵：年齡(Age)、薪水(Salary)，去判斷是走路還是開車代步的例子，紅色的點是走路的人，綠色的點是開車代步的人，而灰色的點則是新加入的一個資料，要預測他是走路還是開車。<br>\n",
    "首先會先將整個流程分成三個大步驟：<br>\n",
    "(1)&ensp;列出根據給定的X的特徵下走路機率的數學表達式。<BR>\n",
    "### $ \\displaystyle P(Walks|X)= \\frac {P(X| Walks)*P(Walks)}{P(X)}$<br>\n",
    "(2)&ensp;列出根據給定的X的特徵下開車代步機率的數學表達式。<BR>\n",
    "### $ \\displaystyle P(Drives|X)= \\frac {P(X| Drives)*P(Drives)}{P(X)}$<br>\n",
    "(3)&ensp;比較這筆資料在兩個分類下面分別的機率來判斷應該屬於那個分類。<BR>\n",
    "### $ P(Walks|X)$ &ensp; $VS$ &ensp; $P(Drives|X)$<HR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 第一個步驟：求出$P(Walks|X)$，原本的數學表達式拆成四個部分：<br>\n",
    "$1.$&ensp;$Prior Probability$&ensp;(先驗機率或事前機率)<br>\n",
    "$2.$&ensp;$Marginal Likelihood$ &ensp; (邊際概似)<br>\n",
    "$3.$&ensp;$Likelihood$&ensp;(概似)<br>\n",
    "$4.$&ensp;$Posterior Probability$&ensp;(後驗機率或事後機率)<br>\n",
    "雖然作者是先算<span style=\"color:red\">邊際概似</span>在算<span style=\"color:red\">概似</span>;，但在下面說明時會先進行<span style=\"color:red\">概似</span>的計算\n",
    "![](images/NaiveBayes3.PNG)<HR>\n",
    "#### $1.$&ensp;$Prior Probability$(先驗機率或事前機率)<br>\n",
    "計算走路的人占全部的人的比例，也就是在整個資料集中抽到走路的機率，將所有的已知資料去計算$P(Walks)$的機率，但不將灰色的點納入計算。<br>\n",
    "$\\displaystyle P(Walks)=\\frac{Number\\ of \\ Walkers}{Total \\ Observations}=\\frac{10}{30}$<br>\n",
    "![](images/NaiveBayes2.PNG)\n",
    "#### $3.$&ensp;$Likelihood$&ensp;(概似)<br>\n",
    "作者在這邊用一個比較簡單的方式去描述計算，以圖為例，以要預測的點為中心，畫一個圓來作為相同特徵的區間代表相似的觀測值，大小可以自由設定。<br>\n",
    "計算走路的人中，具有和新資料點有相同特徵的機率。<br>\n",
    "$\\displaystyle P(X|Walks)=\\frac{Number\\ of\\ Similar\\ Observations\\ Among\\ those \\ who \\ Walk}{Total\\ number\\ of\\ Walkers }=\\frac{3}{10}$<br>\n",
    "![](images/NaiveBayes5.PNG)\n",
    "#### $2.$&ensp;$Marginal Likelihood$ (邊際概似)<br>\n",
    "$\\displaystyle P(X)=\\frac{Number\\ of\\ Similar\\ Observations}{Total\\ Observations}=\\frac{4}{30}$<br>\n",
    "<span style=\"color:red\">補充</span>：\n",
    "##### $ \\displaystyle P(A_k|B)= \\frac {P(B|A_k)*P(A_k)}{P(B)}$ \n",
    "一般的條件機率的$P(X)$是已知的(條件的機率發生在待決定的事件之前)，但貝氏定理中的$P(B)$是需要透過$P(A_i)$與$P(B\\cap A_i)=P(A_i)*P(B|A_i)$，利用全機率公式$P(B)=\\sum_{i=1}^{n} P(A_i)*P(B|A_i)$求出。 <BR>\n",
    "$\\displaystyle P(X)=\\sum_{i=1}^{n} P(A_i)*P(X|A_i)=P(X|Walks)*P(Walks)+P(X|Drives)*P(Drives)=\\frac{3}{10}*\\frac{10}{30}+\\frac{1}{20}*\\frac{20}{30}=\\frac{3}{30}+\\frac{1}{30}=\\frac{4}{30}$<br>\n",
    "![](images/NaiveBayes4.PNG)\n",
    "#### $4.$&ensp;$Posterior Probability$&ensp;(後驗機率或事後機率)<br>\n",
    "$ \\displaystyle P(Walks|X)= \\frac {P(X| Walks)*P(Walks)}{P(X)}=\\frac{\\frac{3}{10}*\\frac{10}{30}}{\\frac{4}{30}}=0.75$<Hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二個步驟：求出$P(Drives|X)$，同上原本的數學表達式拆成四個部分：<br>\n",
    "$1.$&ensp;$Prior Probability$&ensp;(先驗機率或事前機率)<br>\n",
    "$2.$&ensp;$Marginal Likelihood$ &ensp; (邊際概似)<br>\n",
    "$3.$&ensp;$Likelihood$&ensp;(概似)<br>\n",
    "$4.$&ensp;$Posterior Probability$&ensp;(後驗機率或事後機率)<br>\n",
    "雖然作者是先算<span style=\"color:red\">邊際概似</span>在算<span style=\"color:red\">概似</span>;，但在下面說明時會先進行<span style=\"color:red\">概似</span>的計算\n",
    "![](images/NaiveBayes6.PNG)<HR>\n",
    "#### $1.$&ensp;$Prior Probability$(先驗機率或事前機率)<br>\n",
    "計算<span style=\"color:red\">開車代步</span>的人占全部的人的比例，也就是在整個資料集中抽到<span style=\"color:red\">開車代步</span>的機率，將所有的已知資料去計算$P(Drives)$的機率，但不將灰色的點納入計算。<br>\n",
    "$\\displaystyle P(Drives)=\\frac{Number\\ of \\ Drivers}{Total \\ Observations}=\\frac{20}{30}$<br>\n",
    "![](images/NaiveBayes2.PNG)\n",
    "#### $3.$&ensp;$Likelihood$&ensp;(概似)<br>\n",
    "作者在這邊用一個比較簡單的方式去描述計算，以圖為例，以要預測的點為中心，畫一個圓來作為相同特徵的區間代表相似的觀測值，大小可以自由設定。<br>\n",
    "計算<span style=\"color:red\">開車代步</span>的人中，具有和新資料點有相同特徵的機率。<br>\n",
    "$\\displaystyle P(X|Drives)=\\frac{Number\\ of\\ Similar\\ Observations\\ Among\\ those \\ who \\ Drives}{Total\\ number\\ of\\ Drivers }=\\frac{1}{20}$<br>\n",
    "![](images/NaiveBayes7.PNG)\n",
    "#### $2.$&ensp;$Marginal Likelihood$ (邊際概似)<br>\n",
    "$\\displaystyle P(X)=\\frac{Number\\ of\\ Similar\\ Observations}{Total\\ Observations}=\\frac{4}{30}$<br>\n",
    "<span style=\"color:red\">補充</span>：\n",
    "##### $ \\displaystyle P(A_k|B)= \\frac {P(B|A_k)*P(A_k)}{P(B)}$ \n",
    "一般的條件機率的$P(X)$是已知的(條件的機率發生在待決定的事件之前)，但貝氏定理中的$P(B)$是需要透過$P(A_i)$與$P(B\\cap A_i)=P(A_i)*P(B|A_i)$，利用全機率公式$P(B)=\\sum_{i=1}^{n} P(A_i)*P(B|A_i)$求出。 <BR>\n",
    "$\\displaystyle P(X)=\\sum_{i=1}^{n} P(A_i)*P(X|A_i)=P(X|Walks)*P(Walks)+P(X|Drives)*P(Drives)=\\frac{3}{10}*\\frac{10}{30}+\\frac{1}{20}*\\frac{20}{30}=\\frac{3}{30}+\\frac{1}{30}=\\frac{4}{30}$<br>\n",
    "![](images/NaiveBayes4.PNG)\n",
    "#### $4.$&ensp;$Posterior Probability$&ensp;(後驗機率或事後機率)<br>\n",
    "$ \\displaystyle P(Drives|X)= \\frac {P(X|Drives)*P(Drives)}{P(X)}=\\frac{\\frac{1}{20}*\\frac{20}{30}}{\\frac{4}{30}}=0.25$<Hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第三個步驟：比較這筆資料在兩個分類下面分別的機率來判斷應該屬於那個分類<br>\n",
    "#### $ P(Walks|X)$ &ensp; $VS$ &ensp; $P(Drives|X)$<br>\n",
    "$ P(Walks|X)$ &ensp;$=0.75$ &ensp; $VS$ &ensp; $P(Drives|X)$ &ensp;$=0.25$<br>\n",
    "$ P(Walks|X)$ &ensp;$=0.75$ &ensp; <span style=\"color:red\">></span> &ensp; $P(Drives|X)$ &ensp;$=0.25$\n",
    "![](images/NaiveBayes8.PNG)\n",
    "<HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，作者補充三個問題：<br>\n",
    "### 第一：為什麼被稱為 Naive ?<br>\n",
    "Ans：因為貝氏定理有<span style=\"color:red\">**獨立性假設**</span>，而貝氏定理是&ensp;$Naïve$ &ensp; $Bayes$ &ensp;的基礎，但獨立性假設在一般實際的資料似乎無法滿足，所以稱之為一種單純($Naive$)的假設會比較貼切，單純貝氏分類器都假定樣本每個特徵與其他特徵都獨立。。<br>\n",
    "作者以前面上班族的例子來說明：利用估計年薪與年齡對是走路還是開車去做分類，是假設估計年薪和年齡是獨立的，但實際上，年紀較大的人可能會因為經驗而獲得較高的年薪，是有一些相關性在的，因為不獨立，所以理論上應該不能使用貝氏定理，這就是被稱為&ensp;$Naïve$ &ensp; $Bayes$ &ensp;的原因，因為即使變量或特徵不是**獨立**或是**不完全獨立時**，它也能應用並且有不錯的結果。<br>\n",
    "\n",
    "### 第二：$P(X)$ ?<br>\n",
    "在前面的步驟2中，$p(X)$是在欲分類的點為中心，畫一個圈，拿掉要預測的點後，而來自此資料集的隨機選擇點的將會與我們即將添加的數據點顯示相似的特徵，而通常在不同的分類計算上$P(X)$的數值都是一樣的。\n",
    "#### $ P(Walks|X)$ &ensp; $VS$ &ensp; $P(Drives|X)$<br>\n",
    "$ \\displaystyle P(Walks|X)= \\frac {P(X|Walks)*P(Walks)}{P(X)} $&ensp; $VS$ &ensp;\n",
    "$ \\displaystyle P(Drives|X)= \\frac {P(X|Drives)*P(Drives)}{P(X)}$ <br>\n",
    "所以當你在比較兩邊的大小的時候，可以做一個簡化的動作，但如果是想要算出完整的機率值，就不能做省略的步驟。<br>\n",
    "<span style=\"color:red\">補充</span>：<br>\n",
    "![](images/NaiveBayes9.PNG)\n",
    "![](images/NaiveBayes9_1.PNG)\n",
    "![](images/NaiveBayes9_2.PNG)\n",
    "### 第三：如果超過兩個分類 ?<br>\n",
    "在前面的例子中，都是去預測新資料點屬於兩個分類的哪一類，就可以很簡單的用比較大小的方式，例如：\n",
    "#### $ P(Walks|X)$ &ensp; $VS$ &ensp; $P(Drives|X)$<br>\n",
    "$ P(Walks|X)$ &ensp;$=0.75$ &ensp; $VS$ &ensp; $P(Drives|X)$ &ensp;$=0.25$<br>\n",
    "$ P(Walks|X)$ &ensp;$=0.75$ &ensp; <span style=\"color:red\">></span> &ensp; $P(Drives|X)$ &ensp;$=0.25$\n",
    "並且只要算出第一個值，就可以直接得知另一個值，因為相加等於1，所以當分類大於兩類以上時，你需要至少計算其中兩個分類，或是其中一個分類大於0.5以上時可以直接判斷為該分類。<Hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
