{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Classification Models Performance\n",
    "## 122. False Positives & False Negative\n",
    "![122.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/122.png?raw=true)\n",
    "False Positives和False Negative就是所謂的假陽和假陰，也就是常聽到的型一誤差(TYPE I ERROR)和型二誤差(TYPE II ERROR)，<br>\n",
    "白話一點解釋，型一誤差(假陽)就是實際上是不會發生但模型預測會發生，如圖中點#3；<br>\n",
    "型二誤差(假陰)則是實際上是會發生但模型預測不會發生，如圖中點#2，<br>\n",
    "一般來說型二誤差比較嚴重，因為我們關注想要用模型來預測的結果(發生)並沒有被有效預測出來，而型一誤差可把它視為一種警訊。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 123. Confusion Matrix\n",
    "![123.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/123.png?raw=true)\n",
    "混淆矩陣其實在過去課程的模型建立過程中有提到過，它可用來歸納預測結果好壞，列表示實際的結果、行表示預測的結果，<br>\n",
    "所以這個2*2矩陣的左上、右下就是預測準確的部分，右上是發生型一誤差、左下則是發生型二誤差。<br>\n",
    "這個矩陣也能方便我們計算: <br>\n",
    "準確率Accuracy Rate(AR) = correct / total = 85 / 100 = 85%<br>\n",
    "錯誤率Error Rate(ER) = wrong / total = 15 / 100 = 15%<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 124. Accuracy paradox\n",
    "有些狀況下，其實準確率並無法反映模型的好壞，可藉由以下例子理解到:\n",
    "![124.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/124.png?raw=true)\n",
    "如果我們都預測為0，反而使準確度提升，這樣似乎並不合理，因此在發生和不發生數量上有懸殊差異時，不應僅用準確率來衡量模型好壞。\n",
    "![124-2.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/124-2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 125. CAP Curve\n",
    "CAP(Cumulative Accuracy Profile)：評估預測模型效力的一種方式<br>\n",
    "概念是反應隨著抓取的樣本資料百分比量不同，指最有可能發生預測目標(eg. 發生購買行為)的前百分比資料，計算此一情形的模型預測出發生的筆數佔全部樣本資料發生的筆數，能作為模型好壞的評估。<br>\n",
    "先將x軸轉換為%單位，並將樣本依照最有可能發生->不可能發生進行排序，假設total共有100人，分成未購買人數90以及有購買人數10，取前10%(x軸)，共有10人，並找模型配適購買率90%以上，確實有購買的人數為8人，8/10=80%(y軸)，依照此規則，抓取各百分比的資料量，畫出CAP線。<br>\n",
    "Random: 這個模型預測結果是隨機的，代表這模型不具有任何預測能力;<br>\n",
    "Crystal Ball: 完美的預測模型效果。<br>\n",
    "CAP曲線越往左上，表示越接近完美的模型預測效果<br>\n",
    "![125.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/125.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 126. CAP Curve Analysis\n",
    "方法1: 將 CAP 曲線加以量化，以AR來衡量，評分模型的區別力，AR值會介於 0~100% 之間，愈接近 100%表示該模型之預測能力愈佳。<br>\n",
    "其中aP為完美模型與隨機模型間之面積；aR為實際評分模型與隨機模型間之面積。<br>\n",
    "![126.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/126.png?raw=true)\n",
    "方法2: 以50%作為區別度，依照X%座落的數值，可判別此模型的好壞，準則可參考圖中範圍。\n",
    "![126-2.png](https://github.com/TAICHUCHUN/ML-in-py/blob/master/126-2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補充 ROC (Receiver Operating Characteristic)\n",
    "ROC 不等於 CAP<br>\n",
    "其中元素有:<br>\n",
    "<ul>\n",
    "<li>TP 為 True Positive 之意(混淆矩陣右下)，TP%即實際上發生且模型的估計結果也判定發生的比率(Y軸);<br>\n",
    "<li>FN 為 False Negative 之意(混淆矩陣左下)，FN%即實際上發生但模型的估計結果卻未判定是違約的比率，這種錯誤稱為型二誤差(Type II Error)，<br>\n",
    "在這樣的定義之下，TP%+FN%=1。<br>\n",
    "<li>FP 為 False Positive 之意(混淆矩陣右上)，FP%即實際上未發生但模型的估計結果卻判定為發生的比率(X軸)，這種錯誤稱為型一誤差(Type I Error);<br>\n",
    "<li>TN 為 True Negative 之意(混淆矩陣左上)，TN%即實際上未發生且模型的估計結果也判定未發生的比率，<br>\n",
    "這樣的定義之下，FP%+TN%=1。<br>\n",
    "</ul>\n",
    "圖示1:<br>\n",
    "<table border=\"1\">\n",
    "<tbody>\n",
    "<tr><td>實際/預測</td><td>0</td><td>1</td></tr>\n",
    "<tr><td>0</td><td>TN</td><td>FP</td></tr>\n",
    "<tr><td>1</td><td>FN</td><td>TP</td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "圖示2:<br>\n",
    "<table border=\"1\">\n",
    "<tbody>\n",
    "<tr><td>實際/預測</td><td>0</td><td>1</td><td>註解</td></tr>\n",
    "<tr><td>0</td><td>TN% = TN / (TN+FP)</td><td>FP% = FP / (TN+FP)</td><td>TN% + FP% = 100%</td></tr>\n",
    "<tr><td>1</td><td>FN% = FN / (FN+TP)</td><td>TP% = TP / (FN+TP)</td><td>FN% + TP% = 100%</td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "如果僅使用一個閾值，也可以判斷分類器的效果，見下圖:<br>\n",
    "![127-2.png](https://upload.wikimedia.org/wikipedia/commons/3/36/ROC_space-2.png)\n",
    "點與隨機模型曲線距離，是預測效果好壞的評比: 離左上角越近的點預測準確率越高。離右下角越近的點，預測越不準。<br>\n",
    "在圖中A、B、C三者當中，最好的結果是A模型。<br>\n",
    "B模型的結果位於隨機模型曲線(45度)上，準確度是50%。<br>\n",
    "C模型雖然預測準確率最差，甚至比隨機模型還差，低於50%，<br>\n",
    "可是如果我們將C以 (0.5, 0.5) 為中點作一個鏡像後，C'的結果甚至要比A還要好，<br>\n",
    "鏡像的做法，就是不管C模型預測了什麼，就做相反的結論能得到較佳的效果。<br>\n",
    "<br>\n",
    "ROC curve是藉由閾值(門檻值)的調整，得到不同的混淆矩陣，一個混淆矩陣就代表曲線上的一點，所以能夠繪製此分類器的ROC curve。<br>\n",
    "閾值的概念就像是本份講義122節圖中的0.5，模型對於某個事件發生與否以機率表現，而我們針對事件的形態會有超過某一機率值表示它會發生的定義，一般常見的是0.5，但我們是可以彈性調整這個門檻值的，所以當門檻值不同時，混淆矩陣的結果就會不同。<br>\n",
    "![127.jpg](https://github.com/TAICHUCHUN/ML-in-py/blob/master/127.jpg?raw=true)\n",
    "ROC 曲線來看，在同一個 TP%之下，FP%越小，則代表造成的型一誤差越小，代表模型的檢測效力越好，因此ROC 曲線越往左上，ROC 曲線下的面積越大，則代表模型越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
